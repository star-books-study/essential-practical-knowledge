# 2장. 느려진 서비스, 어디부터 봐야 할까

- 다양한 지표가 성능과 관련 -> 네트워크 속도, 디스크 속도, 메모리 크기, 디바이스의 CPU 속도
- 서버 성능과 관련된 중요한 지표 -> 응답 시간과 처리량

## 응답 시간
- 응답 시간 : 사용자의 요청을 처리하는 데 걸리는 시간
- 클라이언트가 서버로 요청을 보내는 과정은 크게 2단계로 이루어진다.
  <img width="595" height="247" alt="image" src="https://github.com/user-attachments/assets/23206c65-eeaf-4bb9-b1f4-62bac81a7329" />
- 하나의 API 요청을 처리하는 데 걸리는 시간은 다음과 같이 구성된다.
  <img width="578" height="166" alt="image" src="https://github.com/user-attachments/assets/e20a4ce3-9159-4f16-a766-4af7292d01ce" />
- 응답 시간은 다음과 같이 2가지로 나누어 측정하기도 한다.
  - TTFB(Time to First Byte): 응답 데이터 중 **첫 번째 바이트**가 도착할 때까지 걸린 시간
  - TTLB(Time to Last Byte): 응답 데이터의 **마지막 바이트**가 도착할 때까지 걸린 시간

- 응답 시간은 API 요청 전송 시간, 서버의 처리 시간, API 응답 전송 시간으로 나뉜다.
- 서버 개발자는 주로 서버의 처리 시간을 확인한다. 서버 처리 시간은 다음과 같은 요소를 포함한다.
  - 로직 수행
  - DB 연동
  - 외부 API 연동
  - 응답 데이터 전송
- 이 중에서도 DB 연동, 외부 API 연동이 큰 비중 차지 => 응답 시간을 줄일 떄 이 둘에 집중


### 처리량
- 처리량 : 단위 시간당 시스템이 처리하는 작업량 (TPS나 RPS로 처리량을 나타냄)
  - TPS : 초당 트랜잭션 수
  - RPS : 초당 요청 수

- 두 방법을 적용하면 TPS를 높일 수 있다.
  - 동시에 처리할 수 있는 요청 수를 늘리거나
  - 처리 시간을 단축해야 한다.
<img width="514" height="317" alt="스크린샷 2025-12-14 오후 10 40 05" src="https://github.com/user-attachments/assets/3038e798-428b-447b-937e-2af11e1ff243" />
- 성능을 개선하려면 먼저 현재 서버의 TPS와 응답시간을 알아야 한다.
- TPS를 확인하는 가장 간단한 방법은 모니터링 시스템을 활용하는 것 (스카우터, 핀포인트, 뉴렐릭)
## 서버 성능 개선 기초
- 트래픽이 증가하면서 성능 문제가 발생하는 주된 이유는 **시스템이 수용할 수 있는 최대 TPS를 초과하는 트래픽이 유입되기 때문**이다. 
- TPS를 높이려면 성능 문제가 발생하는 지점을 찾아야 함
  - 실제 실행 시간 측정 필요 -> 모니터링 도구가 유용

### 수직 확장과 수평 확장
- CPU, 메모리, 디스크 등의 자원을 증가시키는 것 -> `수직 확장` (급한 불을 끄는 방법)
  - 더 빠른 CPU로 바꾸거나 CPU 코어 수를 늘리고 메모리를 확장하고 디스크를 SSD로 변경
<img width="521" height="206" alt="스크린샷 2025-12-14 오후 10 44 45" src="https://github.com/user-attachments/assets/dc2d7857-8ed0-4853-9c60-3e21749a491f" />
  - 장점 : 즉각적인 효과
  - 단점 : 트래픽이 지속해서 증가하면 언젠가 결국 또 성능 문제 발생
- 서버를 추가로 투입해 TPS 높이는 방법 -> `수평 확장`
<img width="547" height="172" alt="스크린샷 2025-12-14 오후 10 46 29" src="https://github.com/user-attachments/assets/3257ef0a-10b6-419f-a235-d3257553cb84" />
  - 무턱대고 서버 추가하지는 말고 실제 병목 지점이 어디인지 파악하는 게 중요
  - DB나 외부 API에 성능 문제가 발생하지 않는 범위내에서만 수평 확장을 해야 효과가 있음

### DB 커넥션 풀
- 서버와 DB는 네트워크 통신을 통해 연결되는데 이때 네트워크 연결을 생성하고 종료하는 데 걸리는 시간은 0.5초에서 1초 이상 소요되기도 한다 -> 응답 시간에 영향
- 이런 문제를 피하기 위해 DB 커넥션 풀 사용
  - DB에 연결된 커넥션을 미리 생성해서 보관
  - 애플리케이션은 DB 작업이 필요할 때 풀에서 커넥션을 가져와 사용하고, 작업이 끝나면 다시 풀에 반환
> 스프링 부트는 HikariCP를 커넥션 풀로 사용

### 커넥션 풀 크기
- 커넥션 풀 크기는 커넥션 풀에 미리 생성해둘 커넥션 개수를 지정하는 설정
  - 커넥션 풀 설정에서 가장 중요
- 풀을 늘리면 무조건 좋은가?
  - 크기 증가 → 동시 실행량 증가 → TPS 상승 “가능”
  - 하지만 DB가 이미 CPU 80% 근접 등 포화라면 풀을 늘릴수록 DB 부하가 더 커지고 쿼리 실행 시간(T)이 늘어 오히려 응답 시간이 악화될 수 있다.
  - 결론: 풀 사이즈는 “DB 상태(특히 CPU/락/IO/슬로우쿼리)”를 보면서 조정해야 한다
- 서버 수평 확장도 DB 입장에선 동시 부하 증가라서 본질적으로 같은 문제를 만든다

### 커넥션 대기 시간
- HikariCP 기본 대기 시간은 30초 → 최악의 경우 응답이 30초를 넘길 수 있음
- 서비스 특성에 따라 다르지만 보통 0.5초 ~ 3초 정도로 짧게 잡는 편이 좋다.
- 대기 시간이 길면:
  - 요청이 계속 쌓이고,
  - 사용자는 답답해서 **취소 후 재요청(새로고침)**을 하고,
  - 서버는 이미 처리하던 작업을 즉시 멈추지 못해 동시 트래픽이 더 증가하는 악순환이 발생할 수 있다.

- 대기 시간이 짧으면:
  - 커넥션이 없을 때 빠르게 일시적 오류(429/503 등) 로 반환 가능
  - 서버가 붙잡고 있는 동시 요청 수를 일정 수준으로 유지해서 폭주를 막는 데 도움

### 최대 유휴 시간, 유효성 검사, 최대 유지 시간
- 트래픽이 없는 새벽 시간대처럼 커넥션이 오래 놀면 DB가 연결을 끊을 수 있음
- 이를 막기 위해 커넥션 풀은 보통 아래 기능을 제공:

  - 최대 유휴 시간(Idle Timeout)
    - 일정 시간 이상 사용되지 않은 커넥션을 풀에서 제거
    - DB의 idle timeout보다 짧게 잡으면, DB가 끊기 전에 풀에서 정리 가능
  - 유효성 검사(Validation)

    - 커넥션이 살아있는지 확인(가져올 때 또는 주기적으로)

    - 경우에 따라 SELECT 1 같은 가벼운 쿼리로 검사

  - 최대 유지 시간(Max Lifetime)

    - 커넥션을 무한히 오래 쓰지 않고, 생성 후 일정 시간 지나면 교체

### 서버 캐시
<img width="452" height="243" alt="스크린샷 2025-12-14 오후 11 09 31" src="https://github.com/user-attachments/assets/0aeb0ceb-2d03-4d9a-8666-3046e0f6c868" />

- `hit rate` = 캐시에 존재한 건수 / 캐시 조회 시도 건수
- 적중률이 높을수록:

  - DB 부하 감소

  - 응답 시간 감소

  - 처리량 증가
 
### 적중률과 삭제 규칙
- 캐시는 메모리 한계로 무한 저장이 불가 → 가득 차면 일부를 제거해야 함.

- LRU: 가장 오래 안 쓴 것 제거

- LFU: 가장 덜 쓴 것 제거

- FIFO: 먼저 들어온 것 먼저 제거

- 추가로 TTL(만료시간) 을 둬서 오래된 데이터는 자동 제거 → 메모리 효율 ⬆️


### 로컬 캐시와 리모트 캐시

<img width="612" height="271" alt="image" src="https://github.com/user-attachments/assets/9401ba49-fb49-4ad5-a917-4c48f65b0bdc" />

- 로컬 캐시(인-프로세스 메모리)

  - 장점: 가장 빠름, 구조 단순(네트워크 없음)

  - 단점:
    - 저장 용량이 서버 메모리에 제한

    - 서버 재시작 시 캐시 소멸 → 재가열(warm-up) 동안 성능 하락

- 리모트 캐시(별도 프로세스/서버, Redis 등)

  - 장점:

    - 캐시 용량을 수평 확장 가능

    - 서버 재시작해도 캐시 유지 → 안정적

- 단점:
  - 네트워크 통신 비용으로 로컬보다 느림

  - 운영 복잡도/비용 증가
 
- 선택 기준 (실무 감각)

  - 데이터 규모 작고 변경 적음(예: 공지 10개 목록) → 로컬 캐시도 충분

  - 데이터 규모 큼/트래픽 많음/빈번히 변경 → 리모트 캐시가 유리

  - 배포가 잦아 서버 재시작이 잦음 → 로컬 캐시 적중률이 자주 무너져서 리모트 캐시 고려 가치 ⬆️
 
### 캐시 사전 적재
- 사전 적재가 필요한 상황

  - 특정 시점에 트래픽이 폭발하는 이벤트성 조회(푸시 후 대량 접속 등)

  - 사용자가 몰리기 전에 미리 캐시에 올려두면:
    - 순간 적중률 급락을 막고

    - DB 부하 폭증을 예방할 수 있다.

### 캐시 무효화
- 캐시 무효화가 중요한 이유

  - 원본(DB)이 바뀌었는데 캐시가 안 바뀌면 오래된 잘못된 데이터가 노출됨

  - 변경에 민감한 데이터(가격, 게시글 내용 등):

    - 변경 즉시 무효화/갱신 필요

  - 여러 서버에 로컬 캐시로만 두면 서버별 불일치 위험 → 리모트 캐시 권장

- 덜 민감한 데이터(인기글 목록 등):

  - TTL로 주기 갱신도 가능(예: 10분 TTL)

### 가비지 컬렉터와 메모리 사용
- GC(가비지 컬렉터) 영향

  - 힙 사용량/객체 수가 많을수록 GC 시간이 길어져 Stop-the-world로 응답 지연 가능

  - 힙을 무작정 줄이면 OOM 위험도 있으니 실사용 패턴 기반으로 조정해야 한다.

- 대량 객체 생성 방지

  - 한 번에 너무 많은 데이터를 응답하지 말기(페이징/조회 범위 제한)
  - 파일 다운로드는 전체를 메모리에 올리지 말고 스트리밍으로 처리
  → 동시 사용자 증가에도 메모리 폭증을 방지

### 정적 자원과 브라우저 캐시
- 정적 파일(이미지/JS/CSS)을 Cache-Control/Expires로 캐싱하면

  - 같은 사용자의 재방문 시 서버 트래픽 감소

  - 렌더링 속도 개선

### 정적 자원과 CDN
- 동시에 많은 사용자가 몰릴 때는?

  - 브라우저 캐시가 있어도 “처음 접속한 사용자들”이 많으면 정적 자원 전송으로 네트워크 포화 가능

- CDN을 쓰면:

  - 사용자와 가까운 엣지에서 제공

  - 오리진 서버 트래픽 감소 + 로딩 속도 개선 + 비용 절감 가능

- 운영 주의사항: “큰 파일 업로드 사고”

  - 실수로 매우 큰 이미지(예: 30MB)를 올리면 트래픽/비용이 폭증할 수 있음

  - 웹서버에서 업로드 크기 제한 같은 안전장치 두는 것이 좋다.
 

### 대기 처리
- 단기 폭증(콘서트 예매 등)의 현실

  - 그 짧은 시간(예: 한 달 중 1시간)을 위해 서버는 늘렸다 줄일 수 있어도 DB는 비용/구조상 쉽게 줄이기 어렵다     → 고정비 증가

- 대기 제어(수용량 제한 + 대기열)의 장점

  - 시스템이 감당 가능한 만큼만 받아 서비스를 안정적으로 유지

- 새로고침 유도(재요청)로 트래픽이 더 폭주하는 문제를 줄임 (새로고침하면 순번이 뒤로 밀리게 설계하면 특히 효과적)
